{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bb62d6d-9873-420c-8cdc-d72ae277618a",
   "metadata": {},
   "source": [
    "Note: following these instructions require permissions to sudo as `analytics-product`, which owns the `canonical_data` database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d95cb734-2034-48fb-8743-8eb736f517ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using Wmfdata v2.0.1, but v2.2.0 is available.\n",
      "\n",
      "To update, run `pip install --upgrade git+https://github.com/wikimedia/wmfdata-python.git@release`.\n",
      "\n",
      "To see the changes, refer to https://github.com/wikimedia/wmfdata-python/blob/release/CHANGELOG.md.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import wmfdata as wmf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1e31fd-b006-4b03-80c9-0ccbd03dbc35",
   "metadata": {},
   "source": [
    "Start by loading the dataset into your own database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be187b2f-e46b-4ab8-9723-1bc2fd24397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nshahquinn-wmf/.conda/envs/2023-10-28T00.57.48_nshahquinn-wmf/lib/python3.10/site-packages/wmfdata/hive.py:46: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  response = pd.read_sql(command, conn)\n"
     ]
    }
   ],
   "source": [
    "MY_DATABASE = \"nshahquinn\"\n",
    "\n",
    "wmf.hive.load_csv(\n",
    "    \"wikis.tsv\",\n",
    "    field_spec=\"\"\"\n",
    "        database_code   STRING  COMMENT 'Same as wiki_db in MediaWiki History, e.g. enwiki', \n",
    "        domain_name     STRING  COMMENT 'e.g. en.wikipedia.org', \n",
    "        database_group  STRING  COMMENT 'e.g. wikipedia',\n",
    "        language_code   STRING  COMMENT 'e.g. en',\n",
    "        mobile_domain_name STRING COMMENT 'e.g. en.m.wikipedia.org',\n",
    "        language_name   STRING  COMMENT 'e.g. English',\n",
    "        status          STRING  COMMENT 'open/closed',\n",
    "        visibility      STRING  COMMENT 'public/private',\n",
    "        editability     STRING  COMMENT 'public/private',\n",
    "        english_name    STRING  COMMENT 'e.g. English Wikipedia'\n",
    "    \"\"\",\n",
    "    db_name=MY_DATABASE,\n",
    "    table_name=\"wikis\",\n",
    "    sep=\"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8341a3d2-21cc-4ceb-b36b-0e06159e7bff",
   "metadata": {},
   "source": [
    "Now, since it's not possible to run `sudo` commands in our Jupyter environment, in a plain SSH connection, run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "328830de-a480-40d5-a057-90b25f20c6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sudo -u analytics-product kerberos-run-command analytics-product hive -e 'DROP TABLE IF EXISTS canonical_data.wikis; CREATE TABLE canonical_data.wikis AS SELECT * FROM nshahquinn.wikis'\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"sudo -u analytics-product kerberos-run-command analytics-product \"\n",
    "    \"hive -e 'DROP TABLE IF EXISTS canonical_data.wikis; \"\n",
    "    f\"CREATE TABLE canonical_data.wikis AS SELECT * FROM {MY_DATABASE}.wikis'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa73560-6044-4e70-bb05-2662a68e0830",
   "metadata": {},
   "source": [
    "Once that has completed, verify that the newly loaded data matches our local copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e73ba42-6e04-43c2-8c4b-93ec1f09c06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = wmf.presto.run(\"\"\"\n",
    "    SELECT *\n",
    "    FROM canonical_data.wikis\n",
    "\"\"\")\n",
    "\n",
    "local = pd.read_csv(\n",
    "    \"wikis.tsv\", \n",
    "    sep=\"\\t\",\n",
    "    # By default, Pandas will parse the string \"nan\" as a null. However, we have\n",
    "    # several wikis in the Southern Min language, which has the code \"nan\". This\n",
    "    # prevents Pandas from interpreting *any* value as null.\n",
    "    keep_default_na = False,\n",
    "    # We still want to be able to represent null values in the TSV. By default, \n",
    "    # Pandas writes nulls as empty fields, so we ask Pandas to interpret\n",
    "    # empty strings (and nothing else) as nulls.\n",
    "    na_values = [\"\"]\n",
    ")\n",
    "\n",
    "assert local.equals(loaded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
